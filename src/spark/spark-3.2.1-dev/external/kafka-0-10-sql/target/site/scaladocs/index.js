Index.PACKAGES = {"org.apache.spark" : [], "org.apache" : [], "org.apache.spark.sql.kafka010" : [{"name" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition", "shortDescription" : "An input partition for continuous Kafka processing.", "members_case class" : [{"member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition#<init>", "error" : "unsupported entity"}, {"label" : "includeHeaders", "tail" : ": Boolean", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition.includeHeaders", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#includeHeaders:Boolean", "kind" : "val"}, {"label" : "failOnDataLoss", "tail" : ": Boolean", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition.failOnDataLoss", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#failOnDataLoss:Boolean", "kind" : "val"}, {"label" : "pollTimeoutMs", "tail" : ": Long", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition.pollTimeoutMs", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#pollTimeoutMs:Long", "kind" : "val"}, {"label" : "kafkaParams", "tail" : ": Map[String, AnyRef]", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition.kafkaParams", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#kafkaParams:java.util.Map[String,Object]", "kind" : "val"}, {"label" : "startOffset", "tail" : ": Long", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition.startOffset", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#startOffset:Long", "kind" : "val"}, {"label" : "topicPartition", "tail" : ": TopicPartition", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousInputPartition.topicPartition", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#topicPartition:org.apache.kafka.common.TopicPartition", "kind" : "val"}, {"label" : "preferredLocations", "tail" : "(): Array[String]", "member" : "org.apache.spark.sql.connector.read.InputPartition.preferredLocations", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#preferredLocations():Array[String]", "kind" : "def"}, {"label" : "synchronized", "tail" : "(arg0: ⇒ T0): T0", "member" : "scala.AnyRef.synchronized", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#synchronized[T0](x$1:=>T0):T0", "kind" : "final def"}, {"label" : "##", "tail" : "(): Int", "member" : "scala.AnyRef.##", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html###():Int", "kind" : "final def"}, {"label" : "!=", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.!=", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#!=(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "==", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.==", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#==(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "ne", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.ne", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#ne(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "eq", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.eq", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#eq(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "finalize", "tail" : "(): Unit", "member" : "scala.AnyRef.finalize", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#finalize():Unit", "kind" : "def"}, {"label" : "wait", "tail" : "(): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#wait():Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long, arg1: Int): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#wait(x$1:Long,x$2:Int):Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#wait(x$1:Long):Unit", "kind" : "final def"}, {"label" : "notifyAll", "tail" : "(): Unit", "member" : "scala.AnyRef.notifyAll", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#notifyAll():Unit", "kind" : "final def"}, {"label" : "notify", "tail" : "(): Unit", "member" : "scala.AnyRef.notify", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#notify():Unit", "kind" : "final def"}, {"label" : "clone", "tail" : "(): AnyRef", "member" : "scala.AnyRef.clone", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#clone():Object", "kind" : "def"}, {"label" : "getClass", "tail" : "(): Class[_]", "member" : "scala.AnyRef.getClass", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#getClass():Class[_]", "kind" : "final def"}, {"label" : "asInstanceOf", "tail" : "(): T0", "member" : "scala.Any.asInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#asInstanceOf[T0]:T0", "kind" : "final def"}, {"label" : "isInstanceOf", "tail" : "(): Boolean", "member" : "scala.Any.isInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html#isInstanceOf[T0]:Boolean", "kind" : "final def"}], "case class" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousInputPartition.html", "kind" : "case class"}, {"name" : "org.apache.spark.sql.kafka010.KafkaContinuousPartitionReader", "shortDescription" : "A per-task data reader for continuous Kafka processing.", "members_class" : [{"label" : "close", "tail" : "(): Unit", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousPartitionReader.close", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#close():Unit", "kind" : "def"}, {"label" : "getOffset", "tail" : "(): KafkaSourcePartitionOffset", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousPartitionReader.getOffset", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#getOffset():org.apache.spark.sql.kafka010.KafkaSourcePartitionOffset", "kind" : "def"}, {"label" : "get", "tail" : "(): UnsafeRow", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousPartitionReader.get", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#get():org.apache.spark.sql.catalyst.expressions.UnsafeRow", "kind" : "def"}, {"label" : "next", "tail" : "(): Boolean", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousPartitionReader.next", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#next():Boolean", "kind" : "def"}, {"member" : "org.apache.spark.sql.kafka010.KafkaContinuousPartitionReader#<init>", "error" : "unsupported entity"}, {"label" : "currentMetricsValues", "tail" : "(): Array[CustomTaskMetric]", "member" : "org.apache.spark.sql.connector.read.PartitionReader.currentMetricsValues", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#currentMetricsValues():Array[org.apache.spark.sql.connector.metric.CustomTaskMetric]", "kind" : "def"}, {"label" : "synchronized", "tail" : "(arg0: ⇒ T0): T0", "member" : "scala.AnyRef.synchronized", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#synchronized[T0](x$1:=>T0):T0", "kind" : "final def"}, {"label" : "##", "tail" : "(): Int", "member" : "scala.AnyRef.##", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html###():Int", "kind" : "final def"}, {"label" : "!=", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.!=", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#!=(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "==", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.==", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#==(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "ne", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.ne", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#ne(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "eq", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.eq", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#eq(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "finalize", "tail" : "(): Unit", "member" : "scala.AnyRef.finalize", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#finalize():Unit", "kind" : "def"}, {"label" : "wait", "tail" : "(): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#wait():Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long, arg1: Int): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#wait(x$1:Long,x$2:Int):Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#wait(x$1:Long):Unit", "kind" : "final def"}, {"label" : "notifyAll", "tail" : "(): Unit", "member" : "scala.AnyRef.notifyAll", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#notifyAll():Unit", "kind" : "final def"}, {"label" : "notify", "tail" : "(): Unit", "member" : "scala.AnyRef.notify", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#notify():Unit", "kind" : "final def"}, {"label" : "toString", "tail" : "(): String", "member" : "scala.AnyRef.toString", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#toString():String", "kind" : "def"}, {"label" : "clone", "tail" : "(): AnyRef", "member" : "scala.AnyRef.clone", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#clone():Object", "kind" : "def"}, {"label" : "equals", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.equals", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#equals(x$1:Any):Boolean", "kind" : "def"}, {"label" : "hashCode", "tail" : "(): Int", "member" : "scala.AnyRef.hashCode", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#hashCode():Int", "kind" : "def"}, {"label" : "getClass", "tail" : "(): Class[_]", "member" : "scala.AnyRef.getClass", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#getClass():Class[_]", "kind" : "final def"}, {"label" : "asInstanceOf", "tail" : "(): T0", "member" : "scala.Any.asInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#asInstanceOf[T0]:T0", "kind" : "final def"}, {"label" : "isInstanceOf", "tail" : "(): Boolean", "member" : "scala.Any.isInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html#isInstanceOf[T0]:Boolean", "kind" : "final def"}], "class" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousPartitionReader.html", "kind" : "class"}, {"name" : "org.apache.spark.sql.kafka010.KafkaContinuousReaderFactory", "shortDescription" : "", "object" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html", "members_object" : [{"label" : "createReader", "tail" : "(partition: InputPartition): ContinuousPartitionReader[InternalRow]", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousReaderFactory.createReader", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#createReader(partition:org.apache.spark.sql.connector.read.InputPartition):org.apache.spark.sql.connector.read.streaming.ContinuousPartitionReader[org.apache.spark.sql.catalyst.InternalRow]", "kind" : "def"}, {"label" : "createColumnarReader", "tail" : "(arg0: InputPartition): ContinuousPartitionReader[ColumnarBatch]", "member" : "org.apache.spark.sql.connector.read.streaming.ContinuousPartitionReaderFactory.createColumnarReader", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#createColumnarReader(x$1:org.apache.spark.sql.connector.read.InputPartition):org.apache.spark.sql.connector.read.streaming.ContinuousPartitionReader[org.apache.spark.sql.vectorized.ColumnarBatch]", "kind" : "def"}, {"label" : "supportColumnarReads", "tail" : "(arg0: InputPartition): Boolean", "member" : "org.apache.spark.sql.connector.read.PartitionReaderFactory.supportColumnarReads", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#supportColumnarReads(x$1:org.apache.spark.sql.connector.read.InputPartition):Boolean", "kind" : "def"}, {"label" : "synchronized", "tail" : "(arg0: ⇒ T0): T0", "member" : "scala.AnyRef.synchronized", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#synchronized[T0](x$1:=>T0):T0", "kind" : "final def"}, {"label" : "##", "tail" : "(): Int", "member" : "scala.AnyRef.##", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html###():Int", "kind" : "final def"}, {"label" : "!=", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.!=", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#!=(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "==", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.==", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#==(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "ne", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.ne", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#ne(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "eq", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.eq", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#eq(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "finalize", "tail" : "(): Unit", "member" : "scala.AnyRef.finalize", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#finalize():Unit", "kind" : "def"}, {"label" : "wait", "tail" : "(): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#wait():Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long, arg1: Int): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#wait(x$1:Long,x$2:Int):Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#wait(x$1:Long):Unit", "kind" : "final def"}, {"label" : "notifyAll", "tail" : "(): Unit", "member" : "scala.AnyRef.notifyAll", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#notifyAll():Unit", "kind" : "final def"}, {"label" : "notify", "tail" : "(): Unit", "member" : "scala.AnyRef.notify", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#notify():Unit", "kind" : "final def"}, {"label" : "toString", "tail" : "(): String", "member" : "scala.AnyRef.toString", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#toString():String", "kind" : "def"}, {"label" : "clone", "tail" : "(): AnyRef", "member" : "scala.AnyRef.clone", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#clone():Object", "kind" : "def"}, {"label" : "equals", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.equals", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#equals(x$1:Any):Boolean", "kind" : "def"}, {"label" : "hashCode", "tail" : "(): Int", "member" : "scala.AnyRef.hashCode", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#hashCode():Int", "kind" : "def"}, {"label" : "getClass", "tail" : "(): Class[_]", "member" : "scala.AnyRef.getClass", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#getClass():Class[_]", "kind" : "final def"}, {"label" : "asInstanceOf", "tail" : "(): T0", "member" : "scala.Any.asInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#asInstanceOf[T0]:T0", "kind" : "final def"}, {"label" : "isInstanceOf", "tail" : "(): Boolean", "member" : "scala.Any.isInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousReaderFactory$.html#isInstanceOf[T0]:Boolean", "kind" : "final def"}], "kind" : "object"}, {"name" : "org.apache.spark.sql.kafka010.KafkaContinuousStream", "shortDescription" : "A ContinuousStream for data from kafka.", "members_class" : [{"label" : "toString", "tail" : "(): String", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.toString", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#toString():String", "kind" : "def"}, {"label" : "needsReconfiguration", "tail" : "(): Boolean", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.needsReconfiguration", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#needsReconfiguration():Boolean", "kind" : "def"}, {"label" : "mergeOffsets", "tail" : "(offsets: Array[PartitionOffset]): Offset", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.mergeOffsets", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#mergeOffsets(offsets:Array[org.apache.spark.sql.connector.read.streaming.PartitionOffset]):org.apache.spark.sql.connector.read.streaming.Offset", "kind" : "def"}, {"label" : "commit", "tail" : "(end: Offset): Unit", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.commit", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#commit(end:org.apache.spark.sql.connector.read.streaming.Offset):Unit", "kind" : "def"}, {"label" : "stop", "tail" : "(): Unit", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.stop", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#stop():Unit", "kind" : "def"}, {"label" : "createContinuousReaderFactory", "tail" : "(): ContinuousPartitionReaderFactory", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.createContinuousReaderFactory", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#createContinuousReaderFactory():org.apache.spark.sql.connector.read.streaming.ContinuousPartitionReaderFactory", "kind" : "def"}, {"label" : "planInputPartitions", "tail" : "(start: Offset): Array[InputPartition]", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.planInputPartitions", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#planInputPartitions(start:org.apache.spark.sql.connector.read.streaming.Offset):Array[org.apache.spark.sql.connector.read.InputPartition]", "kind" : "def"}, {"label" : "deserializeOffset", "tail" : "(json: String): Offset", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.deserializeOffset", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#deserializeOffset(json:String):org.apache.spark.sql.connector.read.streaming.Offset", "kind" : "def"}, {"label" : "initialOffset", "tail" : "(): Offset", "member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream.initialOffset", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#initialOffset():org.apache.spark.sql.connector.read.streaming.Offset", "kind" : "def"}, {"member" : "org.apache.spark.sql.kafka010.KafkaContinuousStream#<init>", "error" : "unsupported entity"}, {"label" : "initializeLogIfNecessary", "tail" : "(isInterpreter: Boolean, silent: Boolean): Boolean", "member" : "org.apache.spark.internal.Logging.initializeLogIfNecessary", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#initializeLogIfNecessary(isInterpreter:Boolean,silent:Boolean):Boolean", "kind" : "def"}, {"label" : "initializeLogIfNecessary", "tail" : "(isInterpreter: Boolean): Unit", "member" : "org.apache.spark.internal.Logging.initializeLogIfNecessary", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#initializeLogIfNecessary(isInterpreter:Boolean):Unit", "kind" : "def"}, {"label" : "isTraceEnabled", "tail" : "(): Boolean", "member" : "org.apache.spark.internal.Logging.isTraceEnabled", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#isTraceEnabled():Boolean", "kind" : "def"}, {"label" : "logError", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logError", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logError(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logWarning", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logWarning", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logWarning(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logTrace", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logTrace", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logTrace(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logDebug", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logDebug", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logDebug(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logInfo", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logInfo", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logInfo(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logError", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logError", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logError(msg:=>String):Unit", "kind" : "def"}, {"label" : "logWarning", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logWarning", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logWarning(msg:=>String):Unit", "kind" : "def"}, {"label" : "logTrace", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logTrace", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logTrace(msg:=>String):Unit", "kind" : "def"}, {"label" : "logDebug", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logDebug", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logDebug(msg:=>String):Unit", "kind" : "def"}, {"label" : "logInfo", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logInfo", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logInfo(msg:=>String):Unit", "kind" : "def"}, {"label" : "log", "tail" : "(): Logger", "member" : "org.apache.spark.internal.Logging.log", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#log:org.slf4j.Logger", "kind" : "def"}, {"label" : "logName", "tail" : "(): String", "member" : "org.apache.spark.internal.Logging.logName", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#logName:String", "kind" : "def"}, {"label" : "synchronized", "tail" : "(arg0: ⇒ T0): T0", "member" : "scala.AnyRef.synchronized", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#synchronized[T0](x$1:=>T0):T0", "kind" : "final def"}, {"label" : "##", "tail" : "(): Int", "member" : "scala.AnyRef.##", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html###():Int", "kind" : "final def"}, {"label" : "!=", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.!=", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#!=(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "==", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.==", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#==(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "ne", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.ne", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#ne(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "eq", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.eq", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#eq(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "finalize", "tail" : "(): Unit", "member" : "scala.AnyRef.finalize", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#finalize():Unit", "kind" : "def"}, {"label" : "wait", "tail" : "(): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#wait():Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long, arg1: Int): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#wait(x$1:Long,x$2:Int):Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#wait(x$1:Long):Unit", "kind" : "final def"}, {"label" : "notifyAll", "tail" : "(): Unit", "member" : "scala.AnyRef.notifyAll", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#notifyAll():Unit", "kind" : "final def"}, {"label" : "notify", "tail" : "(): Unit", "member" : "scala.AnyRef.notify", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#notify():Unit", "kind" : "final def"}, {"label" : "clone", "tail" : "(): AnyRef", "member" : "scala.AnyRef.clone", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#clone():Object", "kind" : "def"}, {"label" : "equals", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.equals", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#equals(x$1:Any):Boolean", "kind" : "def"}, {"label" : "hashCode", "tail" : "(): Int", "member" : "scala.AnyRef.hashCode", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#hashCode():Int", "kind" : "def"}, {"label" : "getClass", "tail" : "(): Class[_]", "member" : "scala.AnyRef.getClass", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#getClass():Class[_]", "kind" : "final def"}, {"label" : "asInstanceOf", "tail" : "(): T0", "member" : "scala.Any.asInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#asInstanceOf[T0]:T0", "kind" : "final def"}, {"label" : "isInstanceOf", "tail" : "(): Boolean", "member" : "scala.Any.isInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html#isInstanceOf[T0]:Boolean", "kind" : "final def"}], "class" : "org\/apache\/spark\/sql\/kafka010\/KafkaContinuousStream.html", "kind" : "class"}, {"name" : "org.apache.spark.sql.kafka010.KafkaMicroBatchStream", "shortDescription" : "", "object" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html", "members_object" : [{"label" : "metrics", "tail" : "(latestConsumedOffset: Optional[Offset], latestAvailablePartitionOffsets: PartitionOffsetMap): Map[String, String]", "member" : "org.apache.spark.sql.kafka010.KafkaMicroBatchStream.metrics", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#metrics(latestConsumedOffset:java.util.Optional[org.apache.spark.sql.connector.read.streaming.Offset],latestAvailablePartitionOffsets:org.apache.spark.sql.kafka010.PartitionOffsetMap):java.util.Map[String,String]", "kind" : "def"}, {"label" : "initializeLogIfNecessary", "tail" : "(isInterpreter: Boolean, silent: Boolean): Boolean", "member" : "org.apache.spark.internal.Logging.initializeLogIfNecessary", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#initializeLogIfNecessary(isInterpreter:Boolean,silent:Boolean):Boolean", "kind" : "def"}, {"label" : "initializeLogIfNecessary", "tail" : "(isInterpreter: Boolean): Unit", "member" : "org.apache.spark.internal.Logging.initializeLogIfNecessary", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#initializeLogIfNecessary(isInterpreter:Boolean):Unit", "kind" : "def"}, {"label" : "isTraceEnabled", "tail" : "(): Boolean", "member" : "org.apache.spark.internal.Logging.isTraceEnabled", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#isTraceEnabled():Boolean", "kind" : "def"}, {"label" : "logError", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logError", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logError(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logWarning", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logWarning", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logWarning(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logTrace", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logTrace", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logTrace(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logDebug", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logDebug", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logDebug(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logInfo", "tail" : "(msg: ⇒ String, throwable: Throwable): Unit", "member" : "org.apache.spark.internal.Logging.logInfo", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logInfo(msg:=>String,throwable:Throwable):Unit", "kind" : "def"}, {"label" : "logError", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logError", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logError(msg:=>String):Unit", "kind" : "def"}, {"label" : "logWarning", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logWarning", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logWarning(msg:=>String):Unit", "kind" : "def"}, {"label" : "logTrace", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logTrace", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logTrace(msg:=>String):Unit", "kind" : "def"}, {"label" : "logDebug", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logDebug", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logDebug(msg:=>String):Unit", "kind" : "def"}, {"label" : "logInfo", "tail" : "(msg: ⇒ String): Unit", "member" : "org.apache.spark.internal.Logging.logInfo", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logInfo(msg:=>String):Unit", "kind" : "def"}, {"label" : "log", "tail" : "(): Logger", "member" : "org.apache.spark.internal.Logging.log", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#log:org.slf4j.Logger", "kind" : "def"}, {"label" : "logName", "tail" : "(): String", "member" : "org.apache.spark.internal.Logging.logName", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#logName:String", "kind" : "def"}, {"label" : "synchronized", "tail" : "(arg0: ⇒ T0): T0", "member" : "scala.AnyRef.synchronized", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#synchronized[T0](x$1:=>T0):T0", "kind" : "final def"}, {"label" : "##", "tail" : "(): Int", "member" : "scala.AnyRef.##", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html###():Int", "kind" : "final def"}, {"label" : "!=", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.!=", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#!=(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "==", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.==", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#==(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "ne", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.ne", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#ne(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "eq", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.eq", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#eq(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "finalize", "tail" : "(): Unit", "member" : "scala.AnyRef.finalize", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#finalize():Unit", "kind" : "def"}, {"label" : "wait", "tail" : "(): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#wait():Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long, arg1: Int): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#wait(x$1:Long,x$2:Int):Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#wait(x$1:Long):Unit", "kind" : "final def"}, {"label" : "notifyAll", "tail" : "(): Unit", "member" : "scala.AnyRef.notifyAll", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#notifyAll():Unit", "kind" : "final def"}, {"label" : "notify", "tail" : "(): Unit", "member" : "scala.AnyRef.notify", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#notify():Unit", "kind" : "final def"}, {"label" : "toString", "tail" : "(): String", "member" : "scala.AnyRef.toString", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#toString():String", "kind" : "def"}, {"label" : "clone", "tail" : "(): AnyRef", "member" : "scala.AnyRef.clone", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#clone():Object", "kind" : "def"}, {"label" : "equals", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.equals", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#equals(x$1:Any):Boolean", "kind" : "def"}, {"label" : "hashCode", "tail" : "(): Int", "member" : "scala.AnyRef.hashCode", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#hashCode():Int", "kind" : "def"}, {"label" : "getClass", "tail" : "(): Class[_]", "member" : "scala.AnyRef.getClass", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#getClass():Class[_]", "kind" : "final def"}, {"label" : "asInstanceOf", "tail" : "(): T0", "member" : "scala.Any.asInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#asInstanceOf[T0]:T0", "kind" : "final def"}, {"label" : "isInstanceOf", "tail" : "(): Boolean", "member" : "scala.Any.isInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaMicroBatchStream$.html#isInstanceOf[T0]:Boolean", "kind" : "final def"}], "kind" : "object"}, {"name" : "org.apache.spark.sql.kafka010.KafkaWrite", "shortDescription" : "", "members_case class" : [{"label" : "toStreaming", "tail" : "(): StreamingWrite", "member" : "org.apache.spark.sql.kafka010.KafkaWrite.toStreaming", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#toStreaming():org.apache.spark.sql.connector.write.streaming.StreamingWrite", "kind" : "def"}, {"label" : "toBatch", "tail" : "(): BatchWrite", "member" : "org.apache.spark.sql.kafka010.KafkaWrite.toBatch", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#toBatch():org.apache.spark.sql.connector.write.BatchWrite", "kind" : "def"}, {"label" : "description", "tail" : "(): String", "member" : "org.apache.spark.sql.kafka010.KafkaWrite.description", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#description():String", "kind" : "def"}, {"member" : "org.apache.spark.sql.kafka010.KafkaWrite#<init>", "error" : "unsupported entity"}, {"label" : "schema", "tail" : ": StructType", "member" : "org.apache.spark.sql.kafka010.KafkaWrite.schema", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#schema:org.apache.spark.sql.types.StructType", "kind" : "val"}, {"label" : "producerParams", "tail" : ": Map[String, AnyRef]", "member" : "org.apache.spark.sql.kafka010.KafkaWrite.producerParams", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#producerParams:java.util.Map[String,Object]", "kind" : "val"}, {"label" : "topic", "tail" : ": Option[String]", "member" : "org.apache.spark.sql.kafka010.KafkaWrite.topic", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#topic:Option[String]", "kind" : "val"}, {"label" : "supportedCustomMetrics", "tail" : "(): Array[CustomMetric]", "member" : "org.apache.spark.sql.connector.write.Write.supportedCustomMetrics", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#supportedCustomMetrics():Array[org.apache.spark.sql.connector.metric.CustomMetric]", "kind" : "def"}, {"label" : "synchronized", "tail" : "(arg0: ⇒ T0): T0", "member" : "scala.AnyRef.synchronized", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#synchronized[T0](x$1:=>T0):T0", "kind" : "final def"}, {"label" : "##", "tail" : "(): Int", "member" : "scala.AnyRef.##", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html###():Int", "kind" : "final def"}, {"label" : "!=", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.!=", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#!=(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "==", "tail" : "(arg0: Any): Boolean", "member" : "scala.AnyRef.==", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#==(x$1:Any):Boolean", "kind" : "final def"}, {"label" : "ne", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.ne", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#ne(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "eq", "tail" : "(arg0: AnyRef): Boolean", "member" : "scala.AnyRef.eq", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#eq(x$1:AnyRef):Boolean", "kind" : "final def"}, {"label" : "finalize", "tail" : "(): Unit", "member" : "scala.AnyRef.finalize", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#finalize():Unit", "kind" : "def"}, {"label" : "wait", "tail" : "(): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#wait():Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long, arg1: Int): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#wait(x$1:Long,x$2:Int):Unit", "kind" : "final def"}, {"label" : "wait", "tail" : "(arg0: Long): Unit", "member" : "scala.AnyRef.wait", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#wait(x$1:Long):Unit", "kind" : "final def"}, {"label" : "notifyAll", "tail" : "(): Unit", "member" : "scala.AnyRef.notifyAll", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#notifyAll():Unit", "kind" : "final def"}, {"label" : "notify", "tail" : "(): Unit", "member" : "scala.AnyRef.notify", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#notify():Unit", "kind" : "final def"}, {"label" : "clone", "tail" : "(): AnyRef", "member" : "scala.AnyRef.clone", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#clone():Object", "kind" : "def"}, {"label" : "getClass", "tail" : "(): Class[_]", "member" : "scala.AnyRef.getClass", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#getClass():Class[_]", "kind" : "final def"}, {"label" : "asInstanceOf", "tail" : "(): T0", "member" : "scala.Any.asInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#asInstanceOf[T0]:T0", "kind" : "final def"}, {"label" : "isInstanceOf", "tail" : "(): Boolean", "member" : "scala.Any.isInstanceOf", "link" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html#isInstanceOf[T0]:Boolean", "kind" : "final def"}], "case class" : "org\/apache\/spark\/sql\/kafka010\/KafkaWrite.html", "kind" : "case class"}], "org.apache.spark.sql" : [], "org" : []};