<!DOCTYPE html >
<html>
        <head>
          <meta http-equiv="X-UA-Compatible" content="IE=edge" />
          <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
          <title>Spark Project SQL 3.2.1 API  - org.apache.spark.sql</title>
          <meta name="description" content="Spark Project SQL 3.2.1 API - org.apache.spark.sql" />
          <meta name="keywords" content="Spark Project SQL 3.2.1 API org.apache.spark.sql" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      
      <link href="../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../../../lib/jquery.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.panzoom.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.mousewheel.min.js"></script>
      <script type="text/javascript" src="../../../../lib/index.js"></script>
      <script type="text/javascript" src="../../../../index.js"></script>
      <script type="text/javascript" src="../../../../lib/scheduler.js"></script>
      <script type="text/javascript" src="../../../../lib/template.js"></script>
      
      <script type="text/javascript">
        /* this variable can be used by the JS to determine the path to the root document */
        var toRoot = '../../../../';
      </script>
    
        </head>
        <body>
      <div id="search">
        <span id="doc-title">Spark Project SQL 3.2.1 API<span id="doc-version"></span></span>
        <span class="close-results"><span class="left">&lt;</span> Back</span>
        <div id="textfilter">
          <span class="input">
            <input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/" />
            <i class="clear material-icons"></i>
            <i id="search-icon" class="material-icons"></i>
          </span>
        </div>
    </div>
      <div id="search-results">
        <div id="search-progress">
          <div id="progress-fill"></div>
        </div>
        <div id="results-content">
          <div id="entity-results"></div>
          <div id="member-results"></div>
        </div>
      </div>
      <div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;">
        <div id="content-container" style="-webkit-overflow-scrolling: touch;">
          <div id="subpackage-spacer">
            <div id="packages">
              <h1>Packages</h1>
              <ul>
                <li name="_root_.root" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="_root_"></a><a id="root:_root_"></a>
      <span class="permalink">
      <a href="../../../../index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../../index.html"><span class="name">root</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="_root_.org" visbl="pub" class="indented1 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="org"></a><a id="org:org"></a>
      <span class="permalink">
      <a href="../../../../org/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../index.html"><span class="name">org</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="org.apache" visbl="pub" class="indented2 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="apache"></a><a id="apache:apache"></a>
      <span class="permalink">
      <a href="../../../../org/apache/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../index.html"><span class="name">apache</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../index.html" class="extype" name="org">org</a></dd></dl></div>
    </li><li name="org.apache.spark" visbl="pub" class="indented3 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="spark"></a><a id="spark:spark"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../index.html"><span class="name">spark</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../index.html" class="extype" name="org.apache">apache</a></dd></dl></div>
    </li><li name="org.apache.spark.api" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="api"></a><a id="api:api"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/api/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../api/index.html"><span class="name">api</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.sql" visbl="pub" class="indented4 current" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sql"></a><a id="sql:sql"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">sql</span>
      </span>
      
      <p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.sql.api" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="api"></a><a id="api:api"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/api/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Contains API classes that are specific to a single language (i.e." href="api/index.html"><span class="name">api</span></a>
      </span>
      
      <p class="shortcomment cmt">Contains API classes that are specific to a single language (i.e.</p><div class="fullcomment"><div class="comment cmt"><p>Contains API classes that are specific to a single language (i.e. Java).
</p></div></div>
    </li><li name="org.apache.spark.sql.catalog" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="catalog"></a><a id="catalog:catalog"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/catalog/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="catalog/index.html"><span class="name">catalog</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.catalyst" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="catalyst"></a><a id="catalyst:catalyst"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/catalyst/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="catalyst/index.html"><span class="name">catalyst</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.columnar" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="columnar"></a><a id="columnar:columnar"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/columnar/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="columnar/index.html"><span class="name">columnar</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.connector" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="connector"></a><a id="connector:connector"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/connector/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="connector/index.html"><span class="name">connector</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.execution" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="execution"></a><a id="execution:execution"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/execution/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="The physical execution component of Spark SQL." href="execution/index.html"><span class="name">execution</span></a>
      </span>
      
      <p class="shortcomment cmt">The physical execution component of Spark SQL.</p><div class="fullcomment"><div class="comment cmt"><p>The physical execution component of Spark SQL. Note that this is a private package.
All classes in catalyst are considered an internal API to Spark SQL and are subject
to change between minor releases.
</p></div></div>
    </li><li name="org.apache.spark.sql.expressions" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="expressions"></a><a id="expressions:expressions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/expressions/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="expressions/index.html"><span class="name">expressions</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.internal" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="internal"></a><a id="internal:internal"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/internal/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="All classes in this package are considered an internal API to Spark and are subject to change between minor releases." href="internal/index.html"><span class="name">internal</span></a>
      </span>
      
      <p class="shortcomment cmt">All classes in this package are considered an internal API to Spark and
are subject to change between minor releases.</p>
    </li><li name="org.apache.spark.sql.jdbc" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="jdbc"></a><a id="jdbc:jdbc"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/jdbc/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="jdbc/index.html"><span class="name">jdbc</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.sources" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="sources"></a><a id="sources:sources"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/sources/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="A set of APIs for adding data sources to Spark SQL." href="sources/index.html"><span class="name">sources</span></a>
      </span>
      
      <p class="shortcomment cmt">A set of APIs for adding data sources to Spark SQL.</p>
    </li><li name="org.apache.spark.sql.streaming" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="streaming"></a><a id="streaming:streaming"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/streaming/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="streaming/index.html"><span class="name">streaming</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.util" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="util"></a><a id="util:util"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/util/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="util/index.html"><span class="name">util</span></a>
      </span>
      
      
    </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="Column.html" title="A column that will be computed based on the data in a DataFrame."></a>
                        <a href="Column.html" title="A column that will be computed based on the data in a DataFrame.">Column</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ColumnName.html" title="A convenient class used for constructing schema."></a>
                        <a href="ColumnName.html" title="A convenient class used for constructing schema.">ColumnName</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="CreateTableWriter.html" title="Trait to restrict calls to create and replace operations."></a>
                        <a href="CreateTableWriter.html" title="Trait to restrict calls to create and replace operations.">CreateTableWriter</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames."></a>
                        <a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames.">DataFrameNaFunctions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g."></a>
                        <a href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g.">DataFrameReader</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameStatFunctions.html" title="Statistic functions for DataFrames."></a>
                        <a href="DataFrameStatFunctions.html" title="Statistic functions for DataFrames.">DataFrameStatFunctions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameWriter.html" title="Interface used to write a Dataset to external storage systems (e.g."></a>
                        <a href="DataFrameWriter.html" title="Interface used to write a Dataset to external storage systems (e.g.">DataFrameWriter</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameWriterV2.html" title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API."></a>
                        <a href="DataFrameWriterV2.html" title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API.">DataFrameWriterV2</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations."></a>
                        <a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations.">Dataset</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DatasetHolder.html" title="A container for a Dataset, used for implicit conversions in Scala."></a>
                        <a href="DatasetHolder.html" title="A container for a Dataset, used for implicit conversions in Scala.">DatasetHolder</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ExperimentalMethods.html" title=":: Experimental :: Holder for experimental methods for the bravest."></a>
                        <a href="ExperimentalMethods.html" title=":: Experimental :: Holder for experimental methods for the bravest.">ExperimentalMethods</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ForeachWriter.html" title="The abstract class for writing custom logic to process data generated by a query."></a>
                        <a href="ForeachWriter.html" title="The abstract class for writing custom logic to process data generated by a query.">ForeachWriter</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key."></a>
                        <a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key.">KeyValueGroupedDataset</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="LowPrioritySQLImplicits.html" title="Lower priority implicit methods for converting Scala objects into Datasets."></a>
                        <a href="LowPrioritySQLImplicits.html" title="Lower priority implicit methods for converting Scala objects into Datasets.">LowPrioritySQLImplicits</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)."></a>
                        <a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot).">RelationalGroupedDataset</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="RuntimeConfig.html" title="Runtime configuration interface for Spark."></a>
                        <a href="RuntimeConfig.html" title="Runtime configuration interface for Spark.">RuntimeConfig</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="SQLContext$.html" title="This SQLContext object contains utility functions to create a singleton SQLContext instance, or to get the created SQLContext instance."></a>
                        <a class="class" href="SQLContext.html" title="The entry point for working with structured data (rows and columns) in Spark 1.x."></a>
                        <a href="SQLContext.html" title="The entry point for working with structured data (rows and columns) in Spark 1.x.">SQLContext</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="SQLImplicits.html" title="A collection of implicit methods for converting common Scala objects into Datasets."></a>
                        <a href="SQLImplicits.html" title="A collection of implicit methods for converting common Scala objects into Datasets.">SQLImplicits</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="SaveMode.html" title="SaveMode is used to specify the expected behavior of saving a DataFrame to a data source."></a>
                        <a href="SaveMode.html" title="SaveMode is used to specify the expected behavior of saving a DataFrame to a data source.">SaveMode</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="SparkSession$.html" title=""></a>
                        <a class="class" href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API."></a>
                        <a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API.">SparkSession</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="SparkSessionExtensions.html" title=":: Experimental :: Holder for injection points to the SparkSession."></a>
                        <a href="SparkSessionExtensions.html" title=":: Experimental :: Holder for injection points to the SparkSession.">SparkSessionExtensions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="SparkSessionExtensionsProvider.html" title=":: Unstable ::"></a>
                        <a href="SparkSessionExtensionsProvider.html" title=":: Unstable ::">SparkSessionExtensionsProvider</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="TypedColumn.html" title="A Column where an Encoder has been given for the expected input and return type."></a>
                        <a href="TypedColumn.html" title="A Column where an Encoder has been given for the expected input and return type.">TypedColumn</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="UDFRegistration.html" title="Functions for registering user-defined functions."></a>
                        <a href="UDFRegistration.html" title="Functions for registering user-defined functions.">UDFRegistration</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="WriteConfigMethods.html" title="Configuration methods common to create/replace operations and insert/overwrite operations."></a>
                        <a href="WriteConfigMethods.html" title="Configuration methods common to create/replace operations and insert/overwrite operations.">WriteConfigMethods</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="object" href="functions$.html" title="Commonly used functions available for DataFrame operations."></a>
                        <a href="functions$.html" title="Commonly used functions available for DataFrame operations.">functions</a>
                      </li><li name="org.apache.spark.status" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="status"></a><a id="status:status"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/status/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../status/index.html"><span class="name">status</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li>
              </ul>
            </div>
          </div>
          <div id="content">
            <body class="package value">
      <div id="definition">
        <div class="big-circle package">p</div>
        <p id="owner"><a href="../../../index.html" class="extype" name="org">org</a>.<a href="../../index.html" class="extype" name="org.apache">apache</a>.<a href="../index.html" class="extype" name="org.apache.spark">spark</a></p>
        <h1>sql<span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span></h1>
        
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">sql</span>
      </span>
      </h4>

      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><div class="toggleContainer block">
          <span class="toggle">
            Linear Supertypes
          </span>
          <div class="superTypes hiddenContent"><span class="extype" name="scala.AnyRef">AnyRef</span>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div class="toggle"></div>
        <div id="memberfilter">
          <i class="material-icons arrow"></i>
          <span class="input">
            <input id="mbrsel-input" placeholder="Filter all members" type="text" accesskey="/" />
          </span>
          <i class="clear material-icons"></i>
        </div>
        <div id="filterby">
          <div id="order">
            <span class="filtertype">Ordering</span>
            <ol>
              
              <li class="alpha in"><span>Alphabetic</span></li>
              <li class="inherit out"><span>By Inheritance</span></li>
            </ol>
          </div>
          <div class="ancestors">
                  <span class="filtertype">Inherited<br />
                  </span>
                  <ol id="linearization">
                    <li class="in" name="org.apache.spark.sql"><span>sql</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                  </ol>
                </div><div class="ancestors">
              <span class="filtertype"></span>
              <ol>
                <li class="hideall out"><span>Hide All</span></li>
                <li class="showall in"><span>Show All</span></li>
              </ol>
            </div>
          <div id="visbl">
              <span class="filtertype">Visibility</span>
              <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
            </div>
        </div>
      </div>

      <div id="template">
        <div id="allMembers">
        

        <div id="types" class="types members">
              <h3>Type Members</h3>
              <ol><li name="org.apache.spark.sql.Column" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ColumnextendsLogging"></a><a id="Column:Column"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Column.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A column that will be computed based on the data in a DataFrame." href="Column.html"><span class="name">Column</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">A column that will be computed based on the data in a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>A column that will be computed based on the data in a <code>DataFrame</code>.</p><p>A new column can be constructed based on the input columns present in a DataFrame:</p><pre>df(<span class="lit">"columnName"</span>)            <span class="cmt">// On a specific `df` DataFrame.</span>
col(<span class="lit">"columnName"</span>)           <span class="cmt">// A generic column not yet associated with a DataFrame.</span>
col(<span class="lit">"columnName.field"</span>)     <span class="cmt">// Extracting a struct field</span>
col(<span class="lit">"`a.column.with.dots`"</span>) <span class="cmt">// Escape `.` in column names.</span>
$<span class="lit">"columnName"</span>               <span class="cmt">// Scala short hand for a named column.</span></pre><p><a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> objects can be composed to form complex expressions:</p><pre>$<span class="lit">"a"</span> + <span class="num">1</span>
$<span class="lit">"a"</span> === $<span class="lit">"b"</span></pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>The internal Catalyst expression can be accessed via <a href="Column.html#expr:org.apache.spark.sql.catalyst.expressions.Expression" class="extmbr" name="org.apache.spark.sql.Column#expr">expr</a>, but this method is for
debugging purposes only and can change in any future Spark releases.</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.ColumnName" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ColumnNameextendsColumn"></a><a id="ColumnName:ColumnName"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/ColumnName.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A convenient class used for constructing schema." href="ColumnName.html"><span class="name">ColumnName</span></a><span class="result"> extends <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      
      <p class="shortcomment cmt">A convenient class used for constructing schema.</p><div class="fullcomment"><div class="comment cmt"><p>A convenient class used for constructing schema.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.CreateTableWriter" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="CreateTableWriter[T]extendsWriteConfigMethods[org.apache.spark.sql.CreateTableWriter[T]]"></a><a id="CreateTableWriter[T]:CreateTableWriter[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/CreateTableWriter.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Trait to restrict calls to create and replace operations." href="CreateTableWriter.html"><span class="name">CreateTableWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="WriteConfigMethods.html" class="extype" name="org.apache.spark.sql.WriteConfigMethods">WriteConfigMethods</a>[<a href="CreateTableWriter.html" class="extype" name="org.apache.spark.sql.CreateTableWriter">CreateTableWriter</a>[<span class="extype" name="org.apache.spark.sql.CreateTableWriter.T">T</span>]]</span>
      </span>
      
      <p class="shortcomment cmt">Trait to restrict calls to create and replace operations.</p><div class="fullcomment"><div class="comment cmt"><p>Trait to restrict calls to create and replace operations.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>3.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]"></a><a id="DataFrame:DataFrame"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">type</span>
      </span>
      <span class="symbol">
        <span class="name">DataFrame</span><span class="result alias"> = <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      
      
    </li><li name="org.apache.spark.sql.DataFrameNaFunctions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameNaFunctionsextendsAnyRef"></a><a id="DataFrameNaFunctions:DataFrameNaFunctions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameNaFunctions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Functionality for working with missing data in DataFrames." href="DataFrameNaFunctions.html"><span class="name">DataFrameNaFunctions</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">Functionality for working with missing data in <code>DataFrame</code>s.</p><div class="fullcomment"><div class="comment cmt"><p>Functionality for working with missing data in <code>DataFrame</code>s.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.1</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameReader" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameReaderextendsLogging"></a><a id="DataFrameReader:DataFrameReader"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Interface used to load a Dataset from external storage systems (e.g." href="DataFrameReader.html"><span class="name">DataFrameReader</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">Interface used to load a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from external storage systems (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>Interface used to load a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from external storage systems (e.g. file systems,
key-value stores, etc). Use <code>SparkSession.read</code> to access this.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameStatFunctions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameStatFunctionsextendsAnyRef"></a><a id="DataFrameStatFunctions:DataFrameStatFunctions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Statistic functions for DataFrames." href="DataFrameStatFunctions.html"><span class="name">DataFrameStatFunctions</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">Statistic functions for <code>DataFrame</code>s.</p><div class="fullcomment"><div class="comment cmt"><p>Statistic functions for <code>DataFrame</code>s.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameWriter" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameWriter[T]extendsAnyRef"></a><a id="DataFrameWriter[T]:DataFrameWriter[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Interface used to write a Dataset to external storage systems (e.g." href="DataFrameWriter.html"><span class="name">DataFrameWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> to external storage systems (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> to external storage systems (e.g. file systems,
key-value stores, etc). Use <code>Dataset.write</code> to access this.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameWriterV2" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameWriterV2[T]extendsCreateTableWriter[T]"></a><a id="DataFrameWriterV2[T]:DataFrameWriterV2[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameWriterV2.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API." href="DataFrameWriterV2.html"><span class="name">DataFrameWriterV2</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="CreateTableWriter.html" class="extype" name="org.apache.spark.sql.CreateTableWriter">CreateTableWriter</a>[<span class="extype" name="org.apache.spark.sql.DataFrameWriterV2.T">T</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">org.apache.spark.sql.Dataset</a> to external storage using the v2 API.</p><div class="fullcomment"><div class="comment cmt"><p>Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">org.apache.spark.sql.Dataset</a> to external storage using the v2 API.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Experimental</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.Dataset" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Dataset[T]extendsSerializable"></a><a id="Dataset[T]:Dataset[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Dataset.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations." href="Dataset.html"><span class="name">Dataset</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A Dataset is a strongly typed collection of domain-specific objects that can be transformed
in parallel using functional or relational operations.</p><div class="fullcomment"><div class="comment cmt"><p>A Dataset is a strongly typed collection of domain-specific objects that can be transformed
in parallel using functional or relational operations. Each Dataset also has an untyped view
called a <code>DataFrame</code>, which is a Dataset of <span class="extype" name="Row">Row</span>.</p><p>Operations available on Datasets are divided into transformations and actions. Transformations
are the ones that produce new Datasets, and actions are the ones that trigger computation and
return results. Example transformations include map, filter, select, and aggregate (<code>groupBy</code>).
Example actions count, show, or writing data out to file systems.</p><p>Datasets are &quot;lazy&quot;, i.e. computations are only triggered when an action is invoked. Internally,
a Dataset represents a logical plan that describes the computation required to produce the data.
When an action is invoked, Spark's query optimizer optimizes the logical plan and generates a
physical plan for efficient execution in a parallel and distributed manner. To explore the
logical plan as well as optimized physical plan, use the <code>explain</code> function.</p><p>To efficiently support domain-specific objects, an <span class="extype" name="Encoder">Encoder</span> is required. The encoder maps
the domain specific type <code>T</code> to Spark's internal type system. For example, given a class <code>Person</code>
with two fields, <code>name</code> (string) and <code>age</code> (int), an encoder is used to tell Spark to generate
code at runtime to serialize the <code>Person</code> object into a binary structure. This binary structure
often has much lower memory footprint as well as are optimized for efficiency in data processing
(e.g. in a columnar format). To understand the internal binary representation for data, use the
<code>schema</code> function.</p><p>There are typically two ways to create a Dataset. The most common way is by pointing Spark
to some files on storage systems, using the <code>read</code> function available on a <code>SparkSession</code>.</p><pre><span class="kw">val</span> people = spark.read.parquet(<span class="lit">"..."</span>).as[Person]  <span class="cmt">// Scala</span>
Dataset&lt;Person&gt; people = spark.read().parquet(<span class="lit">"..."</span>).as(Encoders.bean(Person.<span class="kw">class</span>)); <span class="cmt">// Java</span></pre><p>Datasets can also be created through transformations available on existing Datasets. For example,
the following creates a new Dataset by applying a filter on the existing one:</p><pre><span class="kw">val</span> names = people.map(_.name)  <span class="cmt">// in Scala; names is a Dataset[String]</span>
Dataset&lt;<span class="std">String</span>&gt; names = people.map((Person p) -&gt; p.name, Encoders.STRING));</pre><p>Dataset operations can also be untyped, through various domain-specific-language (DSL)
functions defined in: Dataset (this class), <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>, and <a href="functions$.html" class="extype" name="org.apache.spark.sql.functions">functions</a>. These operations
are very similar to the operations available in the data frame abstraction in R or Python.</p><p>To select a column from the Dataset, use <code>apply</code> method in Scala and <code>col</code> in Java.</p><pre><span class="kw">val</span> ageCol = people(<span class="lit">"age"</span>)  <span class="cmt">// in Scala</span>
Column ageCol = people.col(<span class="lit">"age"</span>); <span class="cmt">// in Java</span></pre><p>Note that the <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> type can also be manipulated through its various functions.</p><pre><span class="cmt">// The following creates a new column that increases everybody's age by 10.</span>
people(<span class="lit">"age"</span>) + <span class="num">10</span>  <span class="cmt">// in Scala</span>
people.col(<span class="lit">"age"</span>).plus(<span class="num">10</span>);  <span class="cmt">// in Java</span></pre><p>A more concrete example in Scala:</p><pre><span class="cmt">// To create Dataset[Row] using SparkSession</span>
<span class="kw">val</span> people = spark.read.parquet(<span class="lit">"..."</span>)
<span class="kw">val</span> department = spark.read.parquet(<span class="lit">"..."</span>)

people.filter(<span class="lit">"age &gt; 30"</span>)
  .join(department, people(<span class="lit">"deptId"</span>) === department(<span class="lit">"id"</span>))
  .groupBy(department(<span class="lit">"name"</span>), people(<span class="lit">"gender"</span>))
  .agg(avg(people(<span class="lit">"salary"</span>)), max(people(<span class="lit">"age"</span>)))</pre><p>and in Java:</p><pre><span class="cmt">// To create Dataset&lt;Row&gt; using SparkSession</span>
Dataset&lt;Row&gt; people = spark.read().parquet(<span class="lit">"..."</span>);
Dataset&lt;Row&gt; department = spark.read().parquet(<span class="lit">"..."</span>);

people.filter(people.col(<span class="lit">"age"</span>).gt(<span class="num">30</span>))
  .join(department, people.col(<span class="lit">"deptId"</span>).equalTo(department.col(<span class="lit">"id"</span>)))
  .groupBy(department.col(<span class="lit">"name"</span>), people.col(<span class="lit">"gender"</span>))
  .agg(avg(people.col(<span class="lit">"salary"</span>)), max(people.col(<span class="lit">"age"</span>)));</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DatasetHolder" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DatasetHolder[T]extendsProductwithSerializable"></a><a id="DatasetHolder[T]:DatasetHolder[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DatasetHolder.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A container for a Dataset, used for implicit conversions in Scala." href="DatasetHolder.html"><span class="name">DatasetHolder</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A container for a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>, used for implicit conversions in Scala.</p><div class="fullcomment"><div class="comment cmt"><p>A container for a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>, used for implicit conversions in Scala.</p><p>To use this, import implicit conversions in SQL:</p><pre><span class="kw">val</span> spark: SparkSession = ...
<span class="kw">import</span> spark.implicits._</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.ExperimentalMethods" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ExperimentalMethodsextendsAnyRef"></a><a id="ExperimentalMethods:ExperimentalMethods"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title=":: Experimental :: Holder for experimental methods for the bravest." href="ExperimentalMethods.html"><span class="name">ExperimentalMethods</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">:: Experimental ::
Holder for experimental methods for the bravest.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Holder for experimental methods for the bravest. We make NO guarantee about the stability
regarding binary compatibility and source compatibility of methods here.</p><pre>spark.experimental.extraStrategies += ...</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Experimental</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.ForeachWriter" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="ForeachWriter[T]extendsSerializable"></a><a id="ForeachWriter[T]:ForeachWriter[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/ForeachWriter.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">abstract </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="The abstract class for writing custom logic to process data generated by a query." href="ForeachWriter.html"><span class="name">ForeachWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">The abstract class for writing custom logic to process data generated by a query.</p><div class="fullcomment"><div class="comment cmt"><p>The abstract class for writing custom logic to process data generated by a query.
This is often used to write the output of a streaming query to arbitrary storage systems.
Any implementation of this base class will be used by Spark in the following way.</p><ul><li>A single instance of this class is responsible of all the data generated by a single task
    in a query. In other words, one instance is responsible for processing one partition of the
    data generated in a distributed manner.</li><li>Any implementation of this class must be serializable because each task will get a fresh
    serialized-deserialized copy of the provided object. Hence, it is strongly recommended that
    any initialization for writing data (e.g. opening a connection or starting a transaction)
    is done after the <code>open(...)</code> method has been called, which signifies that the task is
    ready to generate data.</li><li>The lifecycle of the methods are as follows.</li></ul><p><pre>
  For each partition with `partitionId`:
      For each batch/epoch of streaming data (if its streaming query) with `epochId`:
          Method `open(partitionId, epochId)` is called.
          If `open` returns true:
               For each row in the partition and batch/epoch, method `process(row)` is called.
          Method `close(errorOrNull)` is called with error (if any) seen while processing rows.
</pre></p><p>Important points to note:</p><ul><li>Spark doesn't guarantee same output for (partitionId, epochId), so deduplication
    cannot be achieved with (partitionId, epochId). e.g. source provides different number of
    partitions for some reason, Spark optimization changes number of partitions, etc.
    Refer SPARK-28650 for more details. If you need deduplication on output, try out
    <code>foreachBatch</code> instead.</li><li>The <code>close()</code> method will be called if <code>open()</code> method returns successfully (irrespective
    of the return value), except if the JVM crashes in the middle.</li></ul><p>Scala example:</p><pre>datasetOfString.writeStream.foreach(<span class="kw">new</span> ForeachWriter[<span class="std">String</span>] {

  <span class="kw">def</span> open(partitionId: <span class="std">Long</span>, version: <span class="std">Long</span>): <span class="std">Boolean</span> = {
    <span class="cmt">// open connection</span>
  }

  <span class="kw">def</span> process(record: <span class="std">String</span>) = {
    <span class="cmt">// write string to connection</span>
  }

  <span class="kw">def</span> close(errorOrNull: Throwable): <span class="std">Unit</span> = {
    <span class="cmt">// close the connection</span>
  }
})</pre><p>Java example:</p><pre>datasetOfString.writeStream().foreach(<span class="kw">new</span> ForeachWriter&lt;<span class="std">String</span>&gt;() {

  @Override
  public boolean open(long partitionId, long version) {
    <span class="cmt">// open connection</span>
  }

  @Override
  public void process(<span class="std">String</span> value) {
    <span class="cmt">// write string to connection</span>
  }

  @Override
  public void close(Throwable errorOrNull) {
    <span class="cmt">// close the connection</span>
  }
});</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.KeyValueGroupedDataset" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="KeyValueGroupedDataset[K,V]extendsSerializable"></a><a id="KeyValueGroupedDataset[K,V]:KeyValueGroupedDataset[K,V]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/KeyValueGroupedDataset.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A Dataset has been logically grouped by a user specified grouping key." href="KeyValueGroupedDataset.html"><span class="name">KeyValueGroupedDataset</span></a><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> has been logically grouped by a user specified grouping key.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> has been logically grouped by a user specified grouping key.  Users should not
construct a <a href="KeyValueGroupedDataset.html" class="extype" name="org.apache.spark.sql.KeyValueGroupedDataset">KeyValueGroupedDataset</a> directly, but should instead call <code>groupByKey</code> on
an existing <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.LowPrioritySQLImplicits" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="LowPrioritySQLImplicitsextendsAnyRef"></a><a id="LowPrioritySQLImplicits:LowPrioritySQLImplicits"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/LowPrioritySQLImplicits.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Lower priority implicit methods for converting Scala objects into Datasets." href="LowPrioritySQLImplicits.html"><span class="name">LowPrioritySQLImplicits</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">Lower priority implicit methods for converting Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>Lower priority implicit methods for converting Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.
Conflicting implicits are placed here to disambiguate resolution.</p><p>Reasons for including specific implicits:
newProductEncoder - to disambiguate for <code>List</code>s which are both <code>Seq</code> and <code>Product</code>
</p></div></div>
    </li><li name="org.apache.spark.sql.RelationalGroupedDataset" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="RelationalGroupedDatasetextendsAnyRef"></a><a id="RelationalGroupedDataset:RelationalGroupedDataset"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/RelationalGroupedDataset.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)." href="RelationalGroupedDataset.html"><span class="name">RelationalGroupedDataset</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">A set of methods for aggregations on a <code>DataFrame</code>, created by <a href="Dataset.html#groupBy(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#groupBy">groupBy</a>,
<a href="Dataset.html#cube(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#cube">cube</a> or <a href="Dataset.html#rollup(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#rollup">rollup</a> (and also <code>pivot</code>).</p><div class="fullcomment"><div class="comment cmt"><p>A set of methods for aggregations on a <code>DataFrame</code>, created by <a href="Dataset.html#groupBy(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#groupBy">groupBy</a>,
<a href="Dataset.html#cube(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#cube">cube</a> or <a href="Dataset.html#rollup(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#rollup">rollup</a> (and also <code>pivot</code>).</p><p>The main method is the <code>agg</code> function, which has multiple variants. This class also contains
some first-order statistics such as <code>mean</code>, <code>sum</code> for convenience.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>This class was named <code>GroupedData</code> in Spark 1.x.</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.RuntimeConfig" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="RuntimeConfigextendsAnyRef"></a><a id="RuntimeConfig:RuntimeConfig"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/RuntimeConfig.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Runtime configuration interface for Spark." href="RuntimeConfig.html"><span class="name">RuntimeConfig</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">Runtime configuration interface for Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Runtime configuration interface for Spark. To access this, use <code>SparkSession.conf</code>.</p><p>Options set here are automatically propagated to the Hadoop configuration during I/O.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SQLContextextendsLoggingwithSerializable"></a><a id="SQLContext:SQLContext"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SQLContext.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="The entry point for working with structured data (rows and columns) in Spark 1.x." href="SQLContext.html"><span class="name">SQLContext</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">The entry point for working with structured data (rows and columns) in Spark 1.x.</p><div class="fullcomment"><div class="comment cmt"><p>The entry point for working with structured data (rows and columns) in Spark 1.x.</p><p>As of Spark 2.0, this is replaced by <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a>. However, we are keeping the class
here for backward compatibility.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLImplicits" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="SQLImplicitsextendsLowPrioritySQLImplicits"></a><a id="SQLImplicits:SQLImplicits"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SQLImplicits.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">abstract </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A collection of implicit methods for converting common Scala objects into Datasets." href="SQLImplicits.html"><span class="name">SQLImplicits</span></a><span class="result"> extends <a href="LowPrioritySQLImplicits.html" class="extype" name="org.apache.spark.sql.LowPrioritySQLImplicits">LowPrioritySQLImplicits</a></span>
      </span>
      
      <p class="shortcomment cmt">A collection of implicit methods for converting common Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>A collection of implicit methods for converting common Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SaveMode" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="SaveModeextendsEnum[org.apache.spark.sql.SaveMode]"></a><a id="SaveMode:SaveMode"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SaveMode.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">sealed abstract final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="SaveMode is used to specify the expected behavior of saving a DataFrame to a data source." href="SaveMode.html"><span class="name">SaveMode</span></a><span class="result"> extends <span class="extype" name="java.lang.Enum">Enum</span>[<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a>]</span>
      </span>
      
      <p class="shortcomment cmt">SaveMode is used to specify the expected behavior of saving a DataFrame to a data source.</p><div class="fullcomment"><div class="comment cmt"><p>SaveMode is used to specify the expected behavior of saving a DataFrame to a data source.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SparkSession" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SparkSessionextendsSerializablewithCloseablewithLogging"></a><a id="SparkSession:SparkSession"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSession.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="The entry point to programming Spark with the Dataset and DataFrame API." href="SparkSession.html"><span class="name">SparkSession</span></a><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span> with <span class="extype" name="java.io.Closeable">Closeable</span> with <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">The entry point to programming Spark with the Dataset and DataFrame API.</p><div class="fullcomment"><div class="comment cmt"><p>The entry point to programming Spark with the Dataset and DataFrame API.</p><p>In environments that this has been created upfront (e.g. REPL, notebooks), use the builder
to get an existing session:</p><pre>SparkSession.builder().getOrCreate()</pre><p>The builder can also be used to create a new session:</p><pre>SparkSession.builder
  .master(<span class="lit">"local"</span>)
  .appName(<span class="lit">"Word Count"</span>)
  .config(<span class="lit">"spark.some.config.option"</span>, <span class="lit">"some-value"</span>)
  .getOrCreate()</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SparkSessionExtensions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SparkSessionExtensionsextendsAnyRef"></a><a id="SparkSessionExtensions:SparkSessionExtensions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSessionExtensions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title=":: Experimental :: Holder for injection points to the SparkSession." href="SparkSessionExtensions.html"><span class="name">SparkSessionExtensions</span></a><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">:: Experimental ::
Holder for injection points to the <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a>.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Holder for injection points to the <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a>. We make NO guarantee about the stability
regarding binary compatibility and source compatibility of methods here.</p><p>This current provides the following extension points:</p><ul><li>Analyzer Rules.</li><li>Check Analysis Rules.</li><li>Optimizer Rules.</li><li>Pre CBO Rules.</li><li>Planning Strategies.</li><li>Customized Parser.</li><li>(External) Catalog listeners.</li><li>Columnar Rules.</li><li>Adaptive Query Stage Preparation Rules.</li></ul><p>The extensions can be used by calling <code>withExtensions</code> on the <a href="SparkSession$$Builder.html" class="extype" name="org.apache.spark.sql.SparkSession.Builder">SparkSession.Builder</a>, for
example:</p><pre>SparkSession.builder()
  .master(<span class="lit">"..."</span>)
  .config(<span class="lit">"..."</span>, <span class="kw">true</span>)
  .withExtensions { extensions <span class="kw">=&gt;</span>
    extensions.injectResolutionRule { session <span class="kw">=&gt;</span>
      ...
    }
    extensions.injectParser { (session, parser) <span class="kw">=&gt;</span>
      ...
    }
  }
  .getOrCreate()</pre><p>The extensions can also be used by setting the Spark SQL configuration property
<code>spark.sql.extensions</code>. Multiple extensions can be set using a comma-separated list. For example:</p><pre>SparkSession.builder()
  .master(<span class="lit">"..."</span>)
  .config(<span class="lit">"spark.sql.extensions"</span>, <span class="lit">"org.example.MyExtensions,org.example.YourExtensions"</span>)
  .getOrCreate()

<span class="kw">class</span> MyExtensions <span class="kw">extends</span> Function1[SparkSessionExtensions, <span class="std">Unit</span>] {
  <span class="kw">override</span> <span class="kw">def</span> apply(extensions: SparkSessionExtensions): <span class="std">Unit</span> = {
    extensions.injectResolutionRule { session <span class="kw">=&gt;</span>
      ...
    }
    extensions.injectParser { (session, parser) <span class="kw">=&gt;</span>
      ...
    }
  }
}

<span class="kw">class</span> YourExtensions <span class="kw">extends</span> SparkSessionExtensionsProvider {
  <span class="kw">override</span> <span class="kw">def</span> apply(extensions: SparkSessionExtensions): <span class="std">Unit</span> = {
    extensions.injectResolutionRule { session <span class="kw">=&gt;</span>
      ...
    }
    extensions.injectFunction(...)
  }
}</pre><p>Note that none of the injected builders should assume that the <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a> is fully
initialized and should not touch the session's internals (e.g. the SessionState).
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
                <span class="name">@Experimental</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SparkSessionExtensionsProvider" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="SparkSessionExtensionsProviderextendsorg.apache.spark.sql.SparkSessionExtensions=&gt;Unit"></a><a id="SparkSessionExtensionsProvider:SparkSessionExtensionsProvider"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSessionExtensionsProvider.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title=":: Unstable ::" href="SparkSessionExtensionsProvider.html"><span class="name">SparkSessionExtensionsProvider</span></a><span class="result"> extends (<a href="SparkSessionExtensions.html" class="extype" name="org.apache.spark.sql.SparkSessionExtensions">SparkSessionExtensions</a>) ⇒ <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      
      <p class="shortcomment cmt">:: Unstable ::</p><div class="fullcomment"><div class="comment cmt"><p>:: Unstable ::</p><p>Base trait for implementations used by <a href="SparkSessionExtensions.html" class="extype" name="org.apache.spark.sql.SparkSessionExtensions">SparkSessionExtensions</a></p><p>For example, now we have an external function named <code>Age</code> to register as an extension for SparkSession:</p><pre><span class="kw">package</span> org.apache.spark.examples.extensions

<span class="kw">import</span> org.apache.spark.sql.catalyst.expressions.{CurrentDate, Expression, RuntimeReplaceable, SubtractDates}

<span class="kw">case</span> <span class="kw">class</span> Age(birthday: Expression, child: Expression) <span class="kw">extends</span> RuntimeReplaceable {

  <span class="kw">def</span> <span class="kw">this</span>(birthday: Expression) = <span class="kw">this</span>(birthday, SubtractDates(CurrentDate(), birthday))
  <span class="kw">override</span> <span class="kw">def</span> exprsReplaced: <span class="std">Seq</span>[Expression] = <span class="std">Seq</span>(birthday)
  <span class="kw">override</span> <span class="kw">protected</span> <span class="kw">def</span> withNewChildInternal(newChild: Expression): Expression = copy(newChild)
}</pre><p>We need to create our extension which inherits <a href="SparkSessionExtensionsProvider.html" class="extype" name="org.apache.spark.sql.SparkSessionExtensionsProvider">SparkSessionExtensionsProvider</a>
Example:</p><pre><span class="kw">package</span> org.apache.spark.examples.extensions

<span class="kw">import</span> org.apache.spark.sql.{SparkSessionExtensions, SparkSessionExtensionsProvider}
<span class="kw">import</span> org.apache.spark.sql.catalyst.FunctionIdentifier
<span class="kw">import</span> org.apache.spark.sql.catalyst.expressions.{Expression, ExpressionInfo}

<span class="kw">class</span> MyExtensions <span class="kw">extends</span> SparkSessionExtensionsProvider {
  <span class="kw">override</span> <span class="kw">def</span> apply(v1: SparkSessionExtensions): <span class="std">Unit</span> = {
    v1.injectFunction(
      (<span class="kw">new</span> FunctionIdentifier(<span class="lit">"age"</span>),
        <span class="kw">new</span> ExpressionInfo(classOf[Age].getName, <span class="lit">"age"</span>),
        (children: <span class="std">Seq</span>[Expression]) <span class="kw">=&gt;</span> <span class="kw">new</span> Age(children.head)))
  }
}</pre><p>Then, we can inject <code>MyExtensions</code> in three ways,</p><ul><li>withExtensions of <a href="SparkSession$$Builder.html" class="extype" name="org.apache.spark.sql.SparkSession.Builder">SparkSession.Builder</a></li><li>Config - spark.sql.extensions</li><li><span class="extype" name="java.util.ServiceLoader">java.util.ServiceLoader</span> - Add to src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider</li></ul></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
                <span class="name">@Since</span><span class="args">(<span>
      
      <span class="symbol">&quot;3.2.0&quot;</span>
    </span>)</span>
              
        </dd><dt>Since</dt><dd><p>3.2.0</p></dd><dt>See also</dt><dd><span class="cmt"><p><a href="SparkSessionExtensions.html" class="extype" name="org.apache.spark.sql.SparkSessionExtensions">SparkSessionExtensions</a></p></span><span class="cmt"><p><a href="SparkSession$$Builder.html" class="extype" name="org.apache.spark.sql.SparkSession.Builder">SparkSession.Builder</a></p></span><span class="cmt"><p><span class="extype" name="java.util.ServiceLoader">java.util.ServiceLoader</span></p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.Strategy" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Strategy=org.apache.spark.sql.execution.SparkStrategy"></a><a id="Strategy:Strategy"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html#Strategy=org.apache.spark.sql.execution.SparkStrategy" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">type</span>
      </span>
      <span class="symbol">
        <span class="name">Strategy</span><span class="result alias"> = <a href="execution/SparkStrategy.html" class="extype" name="org.apache.spark.sql.execution.SparkStrategy">SparkStrategy</a></span>
      </span>
      
      <p class="shortcomment cmt">Converts a logical plan into zero or more SparkPlans.</p><div class="fullcomment"><div class="comment cmt"><p>Converts a logical plan into zero or more SparkPlans.  This API is exposed for experimenting
with the query planner and is not designed to be stable across spark releases.  Developers
writing libraries should instead consider using the stable APIs provided in
<a href="sources/index.html" class="extype" name="org.apache.spark.sql.sources">org.apache.spark.sql.sources</a>
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.TypedColumn" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="TypedColumn[-T,U]extendsColumn"></a><a id="TypedColumn[-T,U]:TypedColumn[T,U]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A Column where an Encoder has been given for the expected input and return type." href="TypedColumn.html"><span class="name">TypedColumn</span></a><span class="tparams">[<span name="T">-T</span>, <span name="U">U</span>]</span><span class="result"> extends <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> where an <span class="extype" name="Encoder">Encoder</span> has been given for the expected input and return type.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> where an <span class="extype" name="Encoder">Encoder</span> has been given for the expected input and return type.
To create a <a href="TypedColumn.html" class="extype" name="org.apache.spark.sql.TypedColumn">TypedColumn</a>, use the <code>as</code> function on a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.
</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>The input type expected for this expression.  Can be <code>Any</code> if the expression is type
          checked by the analyzer instead of the compiler (i.e. <code>expr(&quot;sum(...)&quot;)</code>).</p></dd><dt class="tparam">U</dt><dd class="cmt"><p>The output type of this column.</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.UDFRegistration" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="UDFRegistrationextendsLogging"></a><a id="UDFRegistration:UDFRegistration"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Functions for registering user-defined functions." href="UDFRegistration.html"><span class="name">UDFRegistration</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">Functions for registering user-defined functions.</p><div class="fullcomment"><div class="comment cmt"><p>Functions for registering user-defined functions. Use <code>SparkSession.udf</code> to access this:</p><pre>spark.udf</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.WriteConfigMethods" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="WriteConfigMethods[R]extendsAnyRef"></a><a id="WriteConfigMethods[R]:WriteConfigMethods[R]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/WriteConfigMethods.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Configuration methods common to create/replace operations and insert/overwrite operations." href="WriteConfigMethods.html"><span class="name">WriteConfigMethods</span></a><span class="tparams">[<span name="R">R</span>]</span><span class="result"> extends <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      
      <p class="shortcomment cmt">Configuration methods common to create/replace operations and insert/overwrite operations.</p><div class="fullcomment"><div class="comment cmt"><p>Configuration methods common to create/replace operations and insert/overwrite operations.</p></div><dl class="paramcmts block"><dt class="tparam">R</dt><dd class="cmt"><p>builder type to return</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>3.0.0</p></dd></dl></div>
    </li></ol>
            </div>

        

        <div class="values members">
              <h3>Value Members</h3>
              <ol>
                <li name="org.apache.spark.sql.SQLContext" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SQLContext"></a><a id="SQLContext:SQLContext"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SQLContext$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="This SQLContext object contains utility functions to create a singleton SQLContext instance, or to get the created SQLContext instance." href="SQLContext$.html"><span class="name">SQLContext</span></a><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">This SQLContext object contains utility functions to create a singleton SQLContext instance,
or to get the created SQLContext instance.</p><div class="fullcomment"><div class="comment cmt"><p>This SQLContext object contains utility functions to create a singleton SQLContext instance,
or to get the created SQLContext instance.</p><p>It also provides utility functions to support preference for threads in multiple sessions
scenario, setActive could set a SQLContext for current thread, which will be returned by
getOrCreate instead of the global one.
</p></div></div>
    </li><li name="org.apache.spark.sql.SparkSession" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SparkSession"></a><a id="SparkSession:SparkSession"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSession$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="SparkSession$.html"><span class="name">SparkSession</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.functions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="functions"></a><a id="functions:functions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/functions$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="Commonly used functions available for DataFrame operations." href="functions$.html"><span class="name">functions</span></a>
      </span>
      
      <p class="shortcomment cmt">Commonly used functions available for DataFrame operations.</p><div class="fullcomment"><div class="comment cmt"><p>Commonly used functions available for DataFrame operations. Using functions defined here provides
a little bit more compile-time safety to make sure the function exists.</p><p>Spark also includes more built-in functions that are less common and are not defined here.
You can still access them (and all the functions defined here) using the <code>functions.expr()</code> API
and calling them through a SQL expression string. You can find the entire list of functions
at SQL API documentation.</p><p>As an example, <code>isnan</code> is a function that is defined here. You can use <code>isnan(col(&quot;myCol&quot;))</code>
to invoke the <code>isnan</code> function. This way the programming language's compiler ensures <code>isnan</code>
exists and is of the proper form. You can also use <code>expr(&quot;isnan(myCol)&quot;)</code> function to invoke the
same function. In this case, Spark itself will ensure <code>isnan</code> exists when it analyzes the query.</p><p><code>regr_count</code> is an example of a function that is built-in but not defined here, because it is
less commonly used. To invoke it, use <code>expr(&quot;regr_count(yCol, xCol)&quot;)</code>.</p><p>This function APIs usually have methods with <code>Column</code> signature only because it can support not
only <code>Column</code> but also other types such as a native string. The other variants currently exist
for historical reasons.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li>
              </ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.AnyRef">
              <h3>Inherited from <span class="extype" name="scala.AnyRef">AnyRef</span></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
    </body>
          </div>
        </div>
      </div>
    </body>
      </html>
